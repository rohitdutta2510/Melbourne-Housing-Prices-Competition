{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"# Read the data\nimport pandas as pd\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\ntest_full = pd.read_csv(\"../input/test.csv\")\ntrain_full = pd.read_csv(\"../input/train.csv\")\n\n# Remove rows with missing target, separate target from predictors\ntrain_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = train_full.SalePrice\ntrain_full.drop(['SalePrice'], axis=1, inplace=True)\n\n# Separating numerical predictors\ntrain_num = train_full.select_dtypes(exclude=['object'])\ntest_num = test_full.select_dtypes(exclude=['object'])\n\n# Separating catagorical predictors\ntrain_cat = train_full.select_dtypes(include=['object'])\ntest_cat = test_full.select_dtypes(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_num.shape)\nprint(train_cat.shape)\nprint(test_num.shape)\nprint(test_cat.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining function 'score_dataset' to calculate MAE"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imputing numerical predictors with 'median'"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n#Imputation with median\nfinal_imputer = SimpleImputer(strategy=\"median\")\n\n# Preprocessed training and validation features\nfinal_train_num = pd.DataFrame(final_imputer.fit_transform(train_num))\nfinal_test_num = pd.DataFrame(final_imputer.transform(test_num))\n\nfinal_train_num.columns = train_num.columns\nfinal_test_num.columns = test_num.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Treating categorical predictors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_cat.isnull().sum()\n# test_cat.isnull().sum()\n\n# Dropping columns with more than 600 missing values\ndrop_col = [\"Alley\", \"FireplaceQu\", \"PoolQC\", \"Fence\", \"MiscFeature\"]\ntrain_cat.drop(drop_col, axis=1, inplace=True)\ntest_cat.drop(drop_col, axis=1, inplace=True)\n\n'''# Dropping categorical predictors having missing values\ncols_with_missing = [col for col in train_cat.columns if train_cat[col].isnull().any()]\ntrain_cat.drop(cols_with_missing, axis=1, inplace=True)\ntest_cat.drop(cols_with_missing, axis=1, inplace=True)'''\n\nprint(train_cat.shape)\nprint(test_cat.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Imputing categorical columns with missing values by mode\n\ntrain_cols_missing = [col for col in train_cat.columns if train_cat[col].isnull().any()]\nfor column in train_cols_missing:\n    mode = train_cat[column].mode()\n    train_cat[column].fillna(mode[0], inplace=True)\n\n    \ntest_cols_missing = [col for col in test_cat.columns if test_cat[col].isnull().any()]\nfor column in test_cols_missing:\n    mode = test_cat[column].mode()\n    test_cat[column].fillna(mode[0], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"object_cols = [col for col in train_cat.columns if train_cat[col].dtype == \"object\"]\n\n# Columns that will be one-hot encoded\nlow_cardinality_cols = [col for col in object_cols if train_cat[col].nunique() < 10]\n\n# Columns that will be dropped from the dataset\nhigh_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n\nprint('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\nprint('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Onehot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\n# Apply one-hot encoder to each column with categorical data\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_cat[low_cardinality_cols]))\nOH_cols_test = pd.DataFrame(OH_encoder.transform(test_cat[low_cardinality_cols]))\n\n\n# One-hot encoding removed index; put it back\nOH_cols_train.index = train_cat.index\nOH_cols_test.index = test_cat.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train = pd.concat([final_train_num, OH_cols_train], axis=1)\nfinal_test = pd.concat([final_test_num, OH_cols_test], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_train.shape)\nprint(y.shape)\nprint(final_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train-Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(final_train, y, train_size=0.8, test_size=0.2, random_state=0)\n\n# Define and fit model\nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(X_train, y_train)\n\n# Get validation predictions and MAE\ny_preds = model.predict(X_test)\nprint(\"MAE (Median Imputation):\")\nprint(mean_absolute_error(y_test, y_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nmy_model = XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\nmy_model.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)],\n             verbose=False)\npredictions = my_model.predict(X_test)\nprint(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#regressor = RandomForestRegressor(n_estimators=100, random_state=0)\n#regressor.fit(final_train,y)\n\n# Prediction\n#preds_test = regressor.predict(final_test)\n\nregressor = XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\nregressor.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)],\n             verbose=False)\n\n#Prediction\npreds_test = regressor.predict(final_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save test predictions to file\noutput = pd.DataFrame({'Id': final_test.index,\n                       'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}